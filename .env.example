LLM_PROVIDER="ollama" # "gemini", "claude", or "ollama"

GEMINI_API_KEY="YOUR_GEMINI_API_KEY"
GEMINI_MODEL="gemini-2.5-flash-lite" # gemini-2.5-flash, gemini-2.5-pro


ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY"
CLAUDE_MODEL="claude-haiku-4-5" # claude-sonnet-4-5


OLLAMA_BASE_URL="http://localhost:11434"
OLLAMA_MODEL="llama3:70b-instruct" # or "mixtral:8x22b-instruct-v0.1", "qwen2:72b-instruct"